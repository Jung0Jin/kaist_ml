# KAIST_ML

* 기계학습: 인공지능 및 기계학습 개론 Ⅰ, Ⅱ
  * KAIST 산업및시스템공학과 문일철 교수
  * KOOC 강의
    * https://kooc.kaist.ac.kr/machinelearning1_17
    * https://kaist.edwith.org/machinelearning2__17
  * Youtube 
    * https://youtu.be/t6S7ekXz3aY
  * 강의 구성
    1. Motivations and Basics
    2. Fundamentals of Machine Learning
    3. Naïve Bayes Classifier
    4. Logistic Regression
    5. Support Vector Machine
    6. Training/Testing and Regulatization
    7. Bayesian Network
    8. K-Means Clustering and Gaussian Mixture Model
    9. Hidden Markov Model
    10. Sampling Based Inference
  * 참고
    * 심화 강의
      * [(기계학습,인공지능,머신러닝) 한국어 기계 학습 강좌 심화](https://www.youtube.com/playlist?list=PLbhbGI_ppZIRPeAjprW9u9A46IJlGFdLn)

* 스터디 멤버

  * 최슬기: [github](https://github.com/abooun.dev)
  * 유인혁: [github](https://github.com/InhyeokYoo) 
  * 장건희: [github](https://github.com/ckrdkg)
  * 정영진: [github](https://github.com/Jung0Jin)

* 스터디 일정

  * 매주 일요일
  * 오리엔테이션: 21/01/10
  * 기한: 21/01/10~21/05/09

|   |          | 내용                                                        | 강의시간 |
| ------- | -------- | ----------------------------------------------------------- | -------- |
|         |          | [CHAPTER 1. Motivations and Basics](https://github.com/Jung0Jin/kaist_ml/blob/main/CHAPTER1.md)                           | 1:16:15  |
| Study1  | 21/01/17 | 1.1. Motivations                                            | 16:29    |
| Study1  | 21/01/17 | 1.2. MLE                                                    | 21:17    |
| Study1  | 21/01/17 | 1.3. MAP                                                    | 15:36    |
| Study1  | 21/01/17 | 1.4. Probability and Distribution                           | 22:53    |
|         |          | Ch1. Quiz                                                   |          |
|         |          | CHAPTER 2. Fundamentals of Machine Learning                 | 1:38:11  |
| Study2  | 21/01/24 | 2.1. Rule Based Machine Learning Overview                   | 17:30    |
| Study2  | 21/01/24 | 2.2. Introduction to Rule Based Algorithm                   | 24:10:00 |
| Study2  | 21/01/24 | 2.3. Introduction to Decision Tree                          | 9:14     |
| Study2  | 21/01/24 | 2.4. Entropy and Information Gain                           | 24:12:00 |
| Study2  | 21/01/24 | 2.5. How to create a decision tree given a training dataset | 23:05    |
|         |          | Ch2. Quiz                                                   |          |
|         |          | CHAPTER 3. Naive Bayes Classifier                           | 1:11:25  |
| Study3  | 21/01/31 | 3.1. Optimal Classification                                 | 23:42    |
| Study3  | 21/01/31 | 3.2. Conditional Independence                               | 20:53    |
| Study3  | 21/01/31 | 3.3. Naive Bayes Classifier                                 | 8:25     |
| Study3  | 21/01/31 | 3.4. Naive Bayes Classifier Application (Matlab Code)       | 18:25    |
|         |          | Ch3. Quiz                                                   |          |
|         |          | CHAPTER 4. Logistic Regression                              | 2:00:38  |
| Study4  | 21/02/07 | 4.1. Decision Boundary                                      | 18:05    |
| Study4  | 21/02/07 | 4.2. Introduction to Logistic Regression                    | 14:34    |
| Study4  | 21/02/07 | 4.3. Logistic Regression Parameter Approximation 1          | 13:05    |
| Study4  | 21/02/07 | 4.4. Gradient Method                                        | 22:46    |
| Study5  | 21/02/14 | 4.5. How Gradient method works                              | 9:44     |
| Study5  | 21/02/14 | 4.6. Logistic Regression Parameter Approximation 2          | 10:02    |
| Study5  | 21/02/14 | 4.7. Naive Bayes to Logistic Regression                     | 24:09:00 |
| Study5  | 21/02/14 | 4.8. Naive Bayes vs Logistic Regression                     | 8:13     |
|         |          | Ch4. Quiz                                                   |          |
|         |          | CHAPTER 5. Support Vector Machine                           | 1:55:51  |
| Study6  | 21/02/21 | 5.1. Decision Boundary with Margin                          | 17:02    |
| Study6  | 21/02/21 | 5.2. Maximizing the Margin                                  | 12:40    |
| Study6  | 21/02/21 | 5.3. SVM with Matlab                                        | 10:11    |
| Study6  | 21/02/21 | 5.4. Error Handling in SVM                                  | 16:05    |
| Study7  | 21/02/28 | 5.5. Soft Margin with SVM                                   | 12:29    |
| Study7  | 21/02/28 | 5.6. Rethinking of SVM                                      | 10:37    |
| Study7  | 21/02/28 | 5.7. Primal and Dual with KKT Condition                     | 15:49    |
| Study7  | 21/02/28 | 5.8. Kernel                                                 | 9:24     |
| Study7  | 21/02/28 | 5.9. SVM with Kernel                                        | 11:34    |
|         |          | Ch5. Quiz                                                   |          |
|         |          | CHAPTER 6. Training Testing and Regularization              | 1:42:48  |
| Study8  | 21/03/07 | 6.1. Over-fitting and Under-fitting                         | 16:35    |
| Study8  | 21/03/07 | 6.2. Bias and Variance                                      | 19:05    |
| Study8  | 21/03/07 | 6.3. Occam's Razor                                          | 19:53    |
| Study8  | 21/03/07 | 6.4. Cross Validation                                       | 6:28     |
| Study9  | 21/03/14 | 6.5. Performance Metrics                                    | 13:15    |
| Study9  | 21/03/14 | 6.6. Definition of Regularization                           | 14:26    |
| Study9  | 21/03/14 | 6.7. Application of Regularization                          | 13:06    |
|         |          | Ch6. Quiz                                                   |          |
|         |          | CHAPTER 7. Bayesian Network                                 | 2:16:07  |
| Study10 | 21/03/21 | 7.1 Probability Concepts                                    | 10:29    |
| Study10 | 21/03/21 | 7.2 Probability Theorems                                    | 20:56    |
| Study10 | 21/03/21 | 7.3 Interpretation of Bayesian Network                      | 17:18    |
| Study10 | 21/03/21 | 7.4 Bayes Ball Algorithm                                    | 18:03    |
| Study11 | 21/03/28 | 7.5 Factorization of Bayesian networks                      | 7:50     |
| Study11 | 21/03/28 | 7.6 Inference Question on Bayesian network                  | 14:01    |
| Study11 | 21/03/28 | 7.7 Variable Elimination                                    | 13:32    |
| Study11 | 21/03/28 | 7.8 Potential Function and Clique Graph                     | 20:36    |
| Study11 | 21/03/28 | 7.9 Simple Example of Belief Propagation                    | 13:22    |
|         |          | Chapter 7. Quiz                                             |          |
|         |          | CHAPTER 8. K-Means Clustering and Gaussian Mixture Model    | 2:17:57  |
| Study12 | 21/04/04 | 8.1 K-Means Algorithm 1                                     | 18:34    |
| Study12 | 21/04/04 | 8.2 K-Means Algorithm 2                                     | 15:47    |
| Study12 | 21/04/04 | 8.3 Multinomial Distribution                                | 13:25    |
| Study12 | 21/04/04 | 8.4 Multivariate Gaussian Distribution                      | 12:38    |
| Study13 | 21/04/11 | 8.5 Gaussian Mixture Model                                  | 11:13    |
| Study13 | 21/04/11 | 8.6 EM step for Gaussian Mixture Model                      | 20:14    |
| Study13 | 21/04/11 | 8.7 Relation between K-means and GMM                        | 8:22     |
| Study13 | 21/04/11 | 8.8 Fundamentals of the EM Algorithm                        | 14:14    |
| Study13 | 21/04/11 | 8.9 Derivation of EM Algorithm                              | 23:30    |
|         |          | Chapter 8. Quiz                                             |          |
|         |          | CHAPTER 9. Hidden Markov Model                              | 1:48:10  |
| Study14 | 21/04/18 | 9.1 Concept of Hidden Markov Model                          | 19:04    |
| Study14 | 21/04/18 | 9.2 Joint and Marginal Probability of HMM                   | 28:24:00 |
| Study14 | 21/04/18 | 9.3 Forward-Backward probability Calculation                | 15:09    |
| Study14 | 21/04/18 | 9.4 Viterbi Decoding Algorithm                              | 23:59    |
| Study14 | 21/04/18 | 9.5 Baum-Welch Algorithm                                    | 21:34    |
|         |          | Chapter 9. Quiz                                             |          |
|         |          | CHAPTER 10. Sampling Based Inference                        | 3:13:40  |
| Study15 | 21/04/25 | 10.1 Forward Sampling                                       | 10:55    |
| Study15 | 21/04/25 | 10.2 Rejection Sampling                                     | 17:51    |
| Study15 | 21/04/25 | 10.3 Importance Sampling                                    | 14:04    |
| Study15 | 21/04/25 | 10.4 Markov Chain                                           | 25:59:00 |
| Study16 | 21/05/02 | 10.5 Markov Chain for Sampling                              | 8:19     |
| Study16 | 21/05/02 | 10.6 Metropolis-Hastings Algorithm                          | 21:35    |
| Study16 | 21/05/02 | 10.7 Gibbs Sampling                                         | 16:39    |
| Study16 | 21/05/02 | 10.8 Understand the LDA(Latent Dirichlet Allocation)        | 20:25    |
| Study17 | 21/05/09 | 10.9 Gibbs Sampling for LDA - 1                             | 30:51:00 |
| Study17 | 21/05/09 | 10.10 Gibbs Sampling for LDA -2                             | 27:02:00 |
|         |          | Chapter 10. Quiz                                            |          |
